<!DOCTYPE html>
<html>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']], // Ëß£ÊûêË°åÂÜÖÂÖ¨Âºè
        displayMath: [["$$", "$$"], ["\\[", "\\]"]],   //ÊÆµÂÜÖÂÖ¨ÂºèÈÄâÊã©Á¨¶
      },
      svg: {
        fontCache: 'global'
      }
    };
  </script>
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
  </script>
<head>
  <meta charset="utf-8">
  <link rel="author" href="https://shilinyan99.github.io/PanoVOS">   <!-- author profile-->
  <title>PanoVOS: Bridging Non-panoramic and Panoramic Views with Transformer for Video Segmentation</title>
  <meta name="description" content="PanoVOS: Bridging Non-panoramic and Panoramic Views with Transformer for Video Segmentation">
  <meta name="keywords" content="PanoVOS; Panoramic Video Object Segmentation Dataset; PanoVOS: Bridging Non-panoramic and Panoramic Views with Transformer for Video Segmentation; PanoVOS Dataset; Video Object Segmentation; VOS; Video Segmentation; Shilin Yan; Fudan University; Computer Vision">
  
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="PanoVOS: Bridging Non-panoramic and Panoramic Views with Transformer for Video Segmentation">
  <meta property="og:title" content="PanoVOS: Bridging Non-panoramic and Panoramic Views with Transformer for Video Segmentation"/>
  <meta property="og:description" content="PanoVOS: Bridging Non-panoramic and Panoramic Views with Transformer for Video Segmentation"/>
  <meta property="og:url" content="https://shilinyan99.github.io/PanoVOS"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="PanoVOS: Bridging Non-panoramic and Panoramic Views with Transformer for Video Segmentation">
  <meta name="twitter:description" content="PanoVOS: Bridging Non-panoramic and Panoramic Views with Transformer for Video Segmentation">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="PanoVOS; Panoramic Video Object Segmentation Dataset; PanoVOS: Bridging Non-panoramic and Panoramic Views with Transformer for Video Segmentation; PanoVOS Dataset; Video Object Segmentation; VOS; Video Segmentation; Shilin Yan; Fudan University; Computer Vision">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  
  <link rel="icon" type="image/x-icon" href="/favicon_io/favicon.ico">
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon_io/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="favicon_io/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="favicon_io/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="css/bulma.min.css">
  <link rel="stylesheet" href="css/bulma-carousel.min.css">
  <link rel="stylesheet" href="css/bulma-slider.min.css">
  <link rel="stylesheet" href="css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="js/fontawesome.all.min.js"></script>
  <script src="js/bulma-carousel.min.js"></script>
  <script src="js/bulma-slider.min.js"></script>
  <script src="js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">PanoVOS: Bridging Non-panoramic and Panoramic Views with Transformer for Video Segmentation</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=2VhjOykAAAAJ&hl=en" target="_blank">Shilin Yan</a><sup>1</sup>,&nbsp;</span>
                <span class="author-block">
                  <a href="">Xiaohao Xu</a><sup>2</sup>,&nbsp;</span>
                <span class="author-block">
                  <a href="">Lingyi Hong</a><sup>1</sup>,&nbsp;</span>
                <span class="author-block">
                  <a href="" target="_blank">Wenchao Chen</a><sup>1</sup>,&nbsp;</span>
                <span class="author-block">
                  <a href="" target="_blank">Wenqiang Zhang</a><sup>1</sup>,&nbsp;</span>
                <span class="author-block">
                  <a href="" target="_blank">Wei Zhang</a><sup>1</sup></span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                      <sup>1</sup>Fudan University&nbsp;&nbsp;&nbsp;&nbsp;
                      <sup>2</sup>University of Michigan&nbsp;&nbsp;&nbsp;&nbsp;
                      <!-- <sup>3</sup>University of Oxford&nbsp;&nbsp;&nbsp;&nbsp;
                      <sup>4</sup>ByteDance&nbsp;&nbsp;&nbsp;&nbsp;</span> -->
                  </div>
                  
                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
<!--                       <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span> -->
                      <!-- </a>
                    </span> -->

                    <!-- Supplementary PDF link -->
                    <li class="grid">
                      <div class="griditem">
                    <a href="https://arxiv.org/abs/2309.12303" target="_blank" class="imageLink"><img src="DemoImagesPano/paper.png"></a><br><a href="https://arxiv.org/abs/2309.12303" class="PaperLink">üî•Paper</a>
                    </div>
                      </li>
                    <li class="mygrid">
                        <div class="mygriditem">
                      <a href="https://drive.google.com/drive/folders/18dki-y3bTdoLcoJgdvKmaiqcqlUfBgyA?usp=drive_link" target="_blank" class="DatasetLink"><img src="DemoImagesPano/dataset.png"></a><br><a href="https://drive.google.com/drive/folders/18dki-y3bTdoLcoJgdvKmaiqcqlUfBgyA?usp=drive_link" target="_blank">üî•Dataset</a>
                      </div>
                    </li>
                    <li class="mygrid">
                      <div class="mygriditem">
                    <a href="https://github.com/shilinyan99/PanoVOS" target="_blank" class="CodeLink"><img src="DemoImagesPano/github_pad.png"></a><br><a href="https://github.com/shilinyan99/PanoVOS" target="_blank">üî•Code</a>
                    </div>
                  </li>
                  <!-- <span class="link-block">
                      <a href="" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span> -->
                      <!-- <span>üî•Dataset</span>
                      </a>
                  </span> -->
                 
                  <!-- <span class="link-block">
                      <a href="" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                       <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span> -->
                      <!-- <span>üî•Eval Server</span>
                    </a>
                  </span> --> 


                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <center><img src="DemoImagesPano/teaser.png" border="0" width="100%"></center>
      <!-- <h2 class="subtitle has-text-centered"> -->
        <div align="center"><p style="text-align:justify; text-justify:inter-ideograph;width:100%">Figure 1. <b>Panoramic video object segmentation (PanoVOS).</b> PanoVOS targets tracking and distinguishing the particular instances under content discontinuities (e.g. penguin in the image of $T = 15$) and serve distortion (e.g. penguin in the image of $T = 65$). We show the sample of (a) frames, (b) segmentation annotations, and (c) area proportion of foreground for the Penguin video in our dataset.
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p style="text-align:justify; text-justify:inter-ideograph;">
            <b>Panoramic</b> videos contain richer spatial information and have attracted tremendous amounts of attention due to their exceptional experience in some fields such as autonomous driving and virtual reality. However, existing datasets for video segmentation only focus on conventional planar images. To address the challenge, in this paper, we present a panoramic video dataset, <i>i.e.</i>, <b>PanoVOS</b>. The dataset provides 150 videos with high video resolutions and diverse motions. To quantify the domain gap between 2D planar videos and panoramic videos, we evaluate 15 off-the-shelf video object segmentation (VOS) models on PanoVOS. Through error analysis, we found that all of them fail to tackle pixel-level content discontinues of panoramic videos. Thus, we present a Panoramic Space Consistency Transformer (PSCFormer), which can effectively utilize the semantic boundary information of the previous frame for pixel-level matching with the current frame. Extensive experiments demonstrate that compared with the previous SOTA models, our PSCFormer network exhibits a great advantage in terms of segmentation results under the panoramic setting.  Our dataset poses new challenges in panoramic VOS and we hope that our PanoVOS can advance the development of panoramic segmentation/tracking. 
    </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- <section class="section" id="Visualization">
    <div class="container is-max-desktop content">
      <h2 class="title">Visualization</h2>
     <center>
        <img src="DemoImages/webp/0442a954.webp" alt="0442a954" width="224" height="126" />&nbsp;
        <img src="DemoImages/webp/d321dde4.webp" alt="d321dde4" width="224" height="126" />&nbsp;
        <img src="DemoImages/webp/02221fb0.webp" alt="02221fb0" width="224" height="126" />&nbsp;
        <img src="DemoImages/webp/bbe97d18.webp" alt="bbe97d18" width="224" height="126" />&nbsp;
        

        <img src="DemoImages/webp/002b4dce.webp" alt="002b4dce" width="224" height="126" />&nbsp;
        <img src="DemoImages/webp/26ed56e6.webp" alt="26ed56e6" width="224" height="126" />&nbsp;
        <img src="DemoImages/webp/c791ddbb.webp" alt="c791ddbb" width="224" height="126" />&nbsp;      
        <img src="DemoImages/webp/e5e9eb29.webp" alt="e5e9eb29" width="224" height="126" />&nbsp;

      </center>
    </div>
</section> -->



<section class="section" id="Experiments">
  <div class="container is-max-desktop content">
  <h2 class="title">Experiments</h2>
    <!-- <center> -->
     We benchmark the state-of-the-art methods to the best of our knowledge, please see the <a href="https://arxiv.org/abs/2309.12303" target="_blank">PanoVOS Report</a> for details. If your method is more powerful, please feel free to contract us for benchmark evaluation, we will update the results.<br><br>
    
     <center><img src="DemoImagesPano/one-shot-results.png" border="0" width="90%"></center>

     <center><caption><b>TABLE 2. Domain transfer result of (static image datasets + YouTubeVOS)‚Üí(PanoVOS Validation & Test).</b> Subscript $s$ and $u$ denote
      scores in seen and unseen categories. $MF$ denotes multiple historical frames as reference.
      $‚Üì$ represents the performance of the declining 
      values compared to the YouTube-VOS dataset. 
      $‚àó$ denotes a large-scale external dataset BL30K dataset is used during training. 
      $‚Ä†$ denotes no synthetic data is used during the training stage.</caption></center>
     

    <!-- </center> -->
    </div>
</section>

<!-- End image carousel -->
<section class="section" id="Downloads">
  <div class="container is-max-desktop content">
  <h2 class="title">Downloads</h2>
    <center>
      <ul>
        <li class="grid">
          <div class="griditem">
        <a href="" target="_blank" class="imageLink"><img src="DemoImagesPano/paper.png"></a><br><a href="https://arxiv.org/abs/2309.12303" class="imageLink">Technical Report</a>
        </div>
          </li>
         &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

        <li class="mygrid">
          <div class="mygriditem">
        <a href="https://github.com/shilinyan99/PanoVOS" target="_blank" class="imageLink"><img src="DemoImagesPano/dataset.png"></a><br><a href="https://github.com/shilinyan99/PanoVOS" target="_blank">üî•Dataset (ready now!)</a>
        </div>
          </li>
          &nbsp;&nbsp;&nbsp;&nbsp;

        <li li class="mygrid">
          <div class="mygriditem">
        <a href="" target="_blank" class="imageLink"><img src="static/DemoImages/codalab.png"></a><br><a href="https://codalab.lisn.upsaclay.fr/competitions/15928" target="_blank">Online Evaluation </a>
        </div>
          </li>

        </ul><br><br>
      
    </center>
    The dataset is avalibale on <a href="https://drive.google.com/drive/folders/1vChKHzbboP1k6wd6t95guxxURW3nIXBe?usp=sharing" target="_blank">Google Drive</a>, please kindly refer to <a href="https://github.com/shilinyan99/PanoVOS" target="_blank"><b>PanoVOS</b></a> for more details.
    <pre><code><b>üöÄ Download the dataset using <a href="https://pypi.org/project/gdown/" target="_blank">gdown</a> command:</b>
  üéâ train.zip 5.88 GB
  gdown https://drive.google.com/uc?id=178E1TYK7tgj-FXzgnjJyx9gZs2GhQBqr
  üéÜ valid.zip 3.5 GB
  gdown https://drive.google.com/uc?id=10P49VBM7vhGHCqhYvaIjzs7wV0oKLGNl
  üìå test.zip 3.21 GB
  gdown https://drive.google.com/uc?id=1dOiJ55rDP82Fdvm32OYuh1RGMCdHxCMe</code></pre>
  
    </div>
</section> 

<section class="section" id="Evaluation">
  <div class="container is-max-desktop content">
  <h2 class="title">Evaluation</h2>
    <center>
        <li li class="mygrid">
          <div class="mygriditem">
        <a href="" target="_blank" class="imageLink"><img src="DemoImagesPano/codalab.png"></a><br><a href="https://codalab.lisn.upsaclay.fr/competitions/15928" target="_blank">Online Evaluation (üöÄDone!)</a>
        </div>
        </li>
    </center><br><br>

    <font style="line-height:2;">
    ‚óè Following <a href="https://youtube-vos.org/" target="_blank">YouTube-VOS</a>, we use Region Jaccard $\mathcal{J}$ ($\mathcal{J}_{s}$ and $\mathcal{J}_{u}$), Boundary $\mathcal{F}$ measure ($\mathcal{F}_{s}$ and $\mathcal{F}_{u}$), and their mean $\mathcal{J}\&\mathcal{F}$ as the evaluation metrics.<br>

    ‚óè For the validation and test sets, the first-frame annotations are proposed to indicate the objects that will be segmentated. <br>

    ‚óè The validation set online evaluation server is <a href="https://codalab.lisn.upsaclay.fr/competitions/15928">[here]</a> for daily evaluation. (üöÄDone!)<br>

    ‚óè The test set online evaluation server is <a href="https://codalab.lisn.upsaclay.fr/competitions/15928">[here]</a> for daily evaluation. (üöÄDone!)<br>


    <!-- ‚óè <font color="#FF6403">For urgent cases before online server is ready, you could send your predictions to us and we will return the <b><i>J&F</i></b> results to you.</font> -->
    </font>
  </div>
</section>

<!--BibTex citation -->
  <section class="section" id="Citation">
    <div class="container is-max-desktop content">
      <h2 class="title">Citation</h2>
      Please consider to cite PanoVOS if it helps your research.
      <pre><code>@article{yan2023panovos,
  title={PanoVOS: Bridging Non-panoramic and Panoramic Views with Transformer for Video Segmentation},
  author={Yan, Shilin and Xu, Xiaohao and Hong, Lingyi and Chen, Wenchao and Zhang, Wenqiang and Zhang, Wei},
  journal={arXiv preprint arXiv:2309.12303},
  year={2023}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


<section class="section" id="License">
  <div class="container is-max-desktop content">
  <h2 class="title">License</h2>
  <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"  target="_blank"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a></br>
PanoVOS is licensed under a <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0 License</a>. The data of PanoVOS is released for non-commercial research purpose only.
  <!-- </center> -->
    </div>
</section>

<section class="section" id="Contact">
  <div class="container is-max-desktop content">
  <h2 class="title">Contact</h2>
  Any questions, suggestions and feedback are welcomed. Please concat <a href="mailto:tattoo.ysl@gmail.com" target="_blank">tattoo.ysl@gmail.com</a> 
  <!-- </center> -->
    </div>
</section>


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>

            <center><font size=2>¬© Shilin Yan | Last updated: 21/9/2023</font></center>
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
